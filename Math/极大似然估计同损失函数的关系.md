#### 极大似然估计同损失函数的关系

极大似然估计是建模过程中参数估计的一个重要的方法，对于回归问题和分类问题来说，从概率的角度出发，极大似然估计能够推导出不同的损失函数，下面就从这两个方向详细介绍一下损失函数的推导。

##### 分类问题

对于分类来说，假设有样本数据$X=\{(x_1,y_1), (x_2, y_2), \cdots, (x_n,y_n)\}$，其中$x_i\in{R^n}$，$y_i\in{R}$我们想建立一个模型，该模型能够接受一个特征$x$，能够预测出对应$y$的分类，从概率角度考虑即找出最大的$P(y=k|x)$，即我们想找到一个模型能够最大程度的模型出概率分布$P(y=k|x:\theta) $，其中$\theta$定义为模型的参数。

因为是分类问题，假设有$K$个分类$P(y|x:\theta)$可以写成$\prod{P(y=k|x:\theta)^{y_k}}$其中上标$y$是一个one-hot向量。有了对应的概率分布函数，利用极大似然估计去估计模型的参数，对应的似然函数为:
$L = \prod_{i=1}^{n}\prod_{k=1}^{K}p_k^{y_k}$
为了最大化似然函数，将似然函数进行变换，目标函数可以变为：
$argmin-\sum_{i=1}^{n}\sum_{k=1}^{K}y_klogp_k$

如果分类问题是一个二分类问题，假设$k=1$的时候$y=1$，$k=0$的时候$y=0$，根据极大似然估计获得的目标函数就变为了交叉熵损失函数：
$
$argmin-\sum_{i=1}^{n}ylogp$

##### 回归问题

可以参考：https://segmentfault.com/a/1190000018510069中关于MSE的推导


